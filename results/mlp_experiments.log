Using TensorFlow backend.
/home/alfonso/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.1_raw_text_processor_vector_max_words_1000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.283363565923
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.1_raw_text_processor_vector_max_words_1000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.224385554891
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.1_raw_text_processor_vector_max_words_5000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.397633036441
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.1_raw_text_processor_vector_max_words_5000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.269749695959
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.1_raw_text_processor_vector_max_words_7000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.391867733117
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.1_raw_text_processor_vector_max_words_7000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.267136787315
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.1_raw_text_processor_vector_max_words_15000_vectorizer_count.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
30s - loss: 0.1110 - val_loss: 0.0304
Epoch 2/5
29s - loss: 0.0204 - val_loss: 0.0184
Epoch 3/5
29s - loss: 0.0105 - val_loss: 0.0152
Epoch 4/5
29s - loss: 0.0062 - val_loss: 0.0142
Epoch 5/5
28s - loss: 0.0041 - val_loss: 0.0139
Evaluating model...
Best F-score = 0.389668643892
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.1_raw_text_processor_vector_max_words_15000_vectorizer_tfidf.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
16s - loss: 0.1624 - val_loss: 0.0422
Epoch 2/5
15s - loss: 0.0344 - val_loss: 0.0264
Epoch 3/5
14s - loss: 0.0227 - val_loss: 0.0193
Epoch 4/5
15s - loss: 0.0164 - val_loss: 0.0155
Epoch 5/5
14s - loss: 0.0124 - val_loss: 0.0135
Evaluating model...
Best F-score = 0.286794302187
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.2_raw_text_processor_vector_max_words_1000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.272013862404
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.2_raw_text_processor_vector_max_words_1000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.203083672967
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.2_raw_text_processor_vector_max_words_5000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.401779311082
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.2_raw_text_processor_vector_max_words_5000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.262799263615
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.2_raw_text_processor_vector_max_words_7000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.393015885777
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.2_raw_text_processor_vector_max_words_7000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.242029339941
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.2_raw_text_processor_vector_max_words_15000_vectorizer_count.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
33s - loss: 0.1090 - val_loss: 0.0324
Epoch 2/5
33s - loss: 0.0214 - val_loss: 0.0195
Epoch 3/5
33s - loss: 0.0113 - val_loss: 0.0156
Epoch 4/5
33s - loss: 0.0071 - val_loss: 0.0143
Epoch 5/5
33s - loss: 0.0049 - val_loss: 0.0139
Evaluating model...
Best F-score = 0.390055560596
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.2_raw_text_processor_vector_max_words_15000_vectorizer_tfidf.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
19s - loss: 0.1609 - val_loss: 0.0435
Epoch 2/5
16s - loss: 0.0370 - val_loss: 0.0283
Epoch 3/5
17s - loss: 0.0248 - val_loss: 0.0208
Epoch 4/5
16s - loss: 0.0181 - val_loss: 0.0168
Epoch 5/5
17s - loss: 0.0140 - val_loss: 0.0144
Evaluating model...
Best F-score = 0.257415275613
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.5_raw_text_processor_vector_max_words_1000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.235551842177
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.5_raw_text_processor_vector_max_words_1000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.174800379578
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.5_raw_text_processor_vector_max_words_5000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.347720924002
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.5_raw_text_processor_vector_max_words_5000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.201249483092
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.5_raw_text_processor_vector_max_words_7000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.352492314868
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.5_raw_text_processor_vector_max_words_7000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.19871117421
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.5_raw_text_processor_vector_max_words_15000_vectorizer_count.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
19s - loss: 0.1221 - val_loss: 0.0364
Epoch 2/5
19s - loss: 0.0275 - val_loss: 0.0211
Epoch 3/5
19s - loss: 0.0163 - val_loss: 0.0163
Epoch 4/5
19s - loss: 0.0112 - val_loss: 0.0145
Epoch 5/5
18s - loss: 0.0083 - val_loss: 0.0137
Evaluating model...
Best F-score = 0.346385315088
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_200_drop_out_0.5_raw_text_processor_vector_max_words_15000_vectorizer_tfidf.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
13s - loss: 0.1682 - val_loss: 0.0462
Epoch 2/5
12s - loss: 0.0407 - val_loss: 0.0308
Epoch 3/5
11s - loss: 0.0286 - val_loss: 0.0231
Epoch 4/5
11s - loss: 0.0224 - val_loss: 0.0191
Epoch 5/5
11s - loss: 0.0184 - val_loss: 0.0166
Evaluating model...
Best F-score = 0.206402699923
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.1_raw_text_processor_vector_max_words_1000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.329146430342
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.1_raw_text_processor_vector_max_words_1000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.322459308807
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.1_raw_text_processor_vector_max_words_5000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.428532082297
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.1_raw_text_processor_vector_max_words_5000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.382668138232
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.1_raw_text_processor_vector_max_words_7000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.434033866124
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.1_raw_text_processor_vector_max_words_7000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.390869210245
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.1_raw_text_processor_vector_max_words_15000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.430514775876
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.1_raw_text_processor_vector_max_words_15000_vectorizer_tfidf.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
31s - loss: 0.1174 - val_loss: 0.0328
Epoch 2/5
30s - loss: 0.0254 - val_loss: 0.0191
Epoch 3/5
29s - loss: 0.0151 - val_loss: 0.0142
Epoch 4/5
29s - loss: 0.0099 - val_loss: 0.0119
Epoch 5/5
29s - loss: 0.0070 - val_loss: 0.0108
Evaluating model...
Best F-score = 0.387484142158
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.2_raw_text_processor_vector_max_words_1000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.333409586573
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.2_raw_text_processor_vector_max_words_1000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.308865541993
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.2_raw_text_processor_vector_max_words_5000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.426514638017
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.2_raw_text_processor_vector_max_words_5000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.381393136851
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.2_raw_text_processor_vector_max_words_7000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.425633423881
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.2_raw_text_processor_vector_max_words_7000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.382929105745
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.2_raw_text_processor_vector_max_words_15000_vectorizer_count.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
59s - loss: 0.0838 - val_loss: 0.0236
Epoch 2/5
61s - loss: 0.0144 - val_loss: 0.0154
Epoch 3/5
59s - loss: 0.0068 - val_loss: 0.0130
Epoch 4/5
60s - loss: 0.0040 - val_loss: 0.0132
Epoch 5/5
43s - loss: 0.0026 - val_loss: 0.0139
Evaluating model...
Best F-score = 0.431507970267
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.2_raw_text_processor_vector_max_words_15000_vectorizer_tfidf.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
42s - loss: 0.1219 - val_loss: 0.0323
Epoch 2/5
37s - loss: 0.0252 - val_loss: 0.0195
Epoch 3/5
34s - loss: 0.0154 - val_loss: 0.0146
Epoch 4/5
39s - loss: 0.0104 - val_loss: 0.0123
Epoch 5/5
33s - loss: 0.0074 - val_loss: 0.0111
Evaluating model...
Best F-score = 0.378876335195
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.5_raw_text_processor_vector_max_words_1000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.310494278078
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.5_raw_text_processor_vector_max_words_1000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.286997035299
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.5_raw_text_processor_vector_max_words_5000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.430328399039
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.5_raw_text_processor_vector_max_words_5000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.340860590862
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.5_raw_text_processor_vector_max_words_7000_vectorizer_count.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.421979742694
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.5_raw_text_processor_vector_max_words_7000_vectorizer_tfidf.h5
Read previously trained model...
Evaluating model...
Best F-score = 0.341592693057
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.5_raw_text_processor_vector_max_words_15000_vectorizer_count.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
66s - loss: 0.0864 - val_loss: 0.0245
Epoch 2/5
43s - loss: 0.0169 - val_loss: 0.0159
Epoch 3/5
51s - loss: 0.0089 - val_loss: 0.0131
Epoch 4/5
71s - loss: 0.0056 - val_loss: 0.0126
Epoch 5/5
74s - loss: 0.0039 - val_loss: 0.0128
Evaluating model...
Best F-score = 0.415723690052
Best threshold = 0.1
Read previously computed data and targets...
models/mlp_nb_hidden_512_drop_out_0.5_raw_text_processor_vector_max_words_15000_vectorizer_tfidf.h5
Building model...
Training model...
Train on 6992 samples, validate on 777 samples
Epoch 1/5
49s - loss: 0.1262 - val_loss: 0.0347
Epoch 2/5
47s - loss: 0.0283 - val_loss: 0.0212
Epoch 3/5
40s - loss: 0.0184 - val_loss: 0.0160
Epoch 4/5
26s - loss: 0.0132 - val_loss: 0.0134
Epoch 5/5
25s - loss: 0.0102 - val_loss: 0.0121
Evaluating model...
Best F-score = 0.344244014494
Best threshold = 0.1
    drop_out  max_words  nb_hidden     score vectorizer
0        0.1       1000        200  0.283364      count
1        0.1       1000        200  0.224386      tfidf
2        0.1       5000        200  0.397633      count
3        0.1       5000        200  0.269750      tfidf
4        0.1       7000        200  0.391868      count
5        0.1       7000        200  0.267137      tfidf
6        0.1      15000        200  0.389669      count
7        0.1      15000        200  0.286794      tfidf
8        0.2       1000        200  0.272014      count
9        0.2       1000        200  0.203084      tfidf
10       0.2       5000        200  0.401779      count
11       0.2       5000        200  0.262799      tfidf
12       0.2       7000        200  0.393016      count
13       0.2       7000        200  0.242029      tfidf
14       0.2      15000        200  0.390056      count
15       0.2      15000        200  0.257415      tfidf
16       0.5       1000        200  0.235552      count
17       0.5       1000        200  0.174800      tfidf
18       0.5       5000        200  0.347721      count
19       0.5       5000        200  0.201249      tfidf
20       0.5       7000        200  0.352492      count
21       0.5       7000        200  0.198711      tfidf
22       0.5      15000        200  0.346385      count
23       0.5      15000        200  0.206403      tfidf
24       0.1       1000        512  0.329146      count
25       0.1       1000        512  0.322459      tfidf
26       0.1       5000        512  0.428532      count
27       0.1       5000        512  0.382668      tfidf
28       0.1       7000        512  0.434034      count
29       0.1       7000        512  0.390869      tfidf
30       0.1      15000        512  0.430515      count
31       0.1      15000        512  0.387484      tfidf
32       0.2       1000        512  0.333410      count
33       0.2       1000        512  0.308866      tfidf
34       0.2       5000        512  0.426515      count
35       0.2       5000        512  0.381393      tfidf
36       0.2       7000        512  0.425633      count
37       0.2       7000        512  0.382929      tfidf
38       0.2      15000        512  0.431508      count
39       0.2      15000        512  0.378876      tfidf
40       0.5       1000        512  0.310494      count
41       0.5       1000        512  0.286997      tfidf
42       0.5       5000        512  0.430328      count
43       0.5       5000        512  0.340861      tfidf
44       0.5       7000        512  0.421980      count
45       0.5       7000        512  0.341593      tfidf
46       0.5      15000        512  0.415724      count
47       0.5      15000        512  0.344244      tfidf
drop_out           0.1
max_words         7000
nb_hidden          512
score         0.434034
vectorizer       count
Name: 28, dtype: object
